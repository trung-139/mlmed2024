# -*- coding: utf-8 -*-
"""COVID-QU-Ex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1roYpbGgeTRc8av0TOUo_HqHze6LWhgBm
"""

!pip install kaggle

# Commented out IPython magic to ensure Python compatibility.
# %pip install segmentation-models
# %pip install albumentations

# Commented out IPython magic to ensure Python compatibility.
import cv2
import matplotlib.pyplot as plt
import numpy as np
import numpy as np
import tensorflow as tf
import pandas as pd
from tqdm import tqdm
import os
from glob import glob
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.colors as col
from tqdm import tqdm

import matplotlib.colors as col

import albumentations as A
import tensorflow as tf
from tensorflow import keras
from keras.models import load_model, save_model
from tensorflow.keras.models import *
from tensorflow.keras.losses import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.metrics import *
from keras.losses import binary_crossentropy
from keras.models import Model
import tensorflow.keras.backend as K
from tensorflow.keras.preprocessing.image import load_img, img_to_array
os.environ['SM_FRAMEWORK'] = 'tf.keras'
import segmentation_models as sm
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras import backend as keras
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dropout
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split

import os
from kaggle.api import KaggleApi
# Set your Kaggle API credentials
os.environ['KAGGLE_USERNAME'] = 'trungphmxun'
os.environ['KAGGLE_KEY'] = '55f4e742a03f6ad0066e9bd29003ec4b'

# Initialize Kaggle API
api = KaggleApi()
api.authenticate()

# Replace 'dataset-owner/dataset-name' with the actual owner and name of the dataset you want to download
dataset_name = 'anasmohammedtahir/covidqu'

# Download the dataset
api.dataset_download_files(dataset_name, unzip=True)

IMAGE_SIZE = 224
BATCH_SIZE= 8
EPOCHS=50
labels=["Lung","Infection"]

TRAIN_DIR = '/content/Infection Segmentation Data/Infection Segmentation Data/Train/'
TEST_DIR = '/content/Infection Segmentation Data/Infection Segmentation Data/Test'
VALID_DIR = '/content/Infection Segmentation Data/Infection Segmentation Data/Val'

def create_dataframe_from_directory(data_dir):
    image_paths, categories, lung_paths, infection_paths = [], [], [], []
    for fold in os.listdir(data_dir):
        image_path = os.path.join(data_dir, fold, 'images')
        image_paths.extend([os.path.join(image_path, file)
                           for file in os.listdir(image_path)])

        lung_path = os.path.join(data_dir, fold, 'lung masks')
        lung_paths.extend([os.path.join(lung_path, file)
                          for file in os.listdir(lung_path)])

        infection_path = os.path.join(data_dir, fold, 'infection masks')
        infection_paths.extend([os.path.join(infection_path, file)
                               for file in os.listdir(infection_path)])

        categories.extend([fold] * len(os.listdir(image_path)))

    return pd.DataFrame({
        'image': image_paths,
        'category': categories,
        'lung': lung_paths,
        'infection': infection_paths
    })

train_df = create_dataframe_from_directory(TRAIN_DIR)
train_df.head()

valid_df = create_dataframe_from_directory(VALID_DIR)
valid_df.head()

test_df = create_dataframe_from_directory(TEST_DIR)
test_df.head(5)

def plot_sample(image, lung_mask, infection_mask):
    fig, ax = plt.subplots(1, 4, figsize=(12, 14))
    colors = ['green', 'red']

    cmap1 = col.ListedColormap(colors[0])
    cmap2 = col.ListedColormap(colors[1])

    ax[0].imshow(image, cmap="gray")
    ax[0].set_title("Image", fontsize=12, y=1.01)
    ax[0].axis("off")
    # --------------------------
    ax[1].imshow(lung_mask, cmap="gray")
    ax[1].set_title("Lung Mask", fontsize=12, y=1.01)
    ax[1].axis("off")
    # --------------------------
    ax[2].imshow(infection_mask, cmap="gray")
    ax[2].set_title("Infection Mask", fontsize=12, y=1.01)
    ax[2].axis("off")
    # --------------------------
    ax[3].imshow(image, cmap="gray")
    ax[3].set_title("Image & Mask", fontsize=12, y=1.01)
    ax[3].axis("off")
    ax[3].imshow(np.ma.masked_where(lung_mask == False, lung_mask), cmap=cmap1, alpha=1)
    ax[3].imshow(np.ma.masked_where(infection_mask == False, infection_mask), cmap=cmap2, alpha=1)

def process_path(path, color_mode="grayscale"):
    image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE), color_mode=color_mode)
    image = img_to_array(image) / 255.0
    return image

def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def iou_coef(y_true, y_pred, smooth=1):
    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])
    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection
    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)
    return iou

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = y_true_f * y_pred_f
    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return 1. - score

def bce_dice_loss(y_true, y_pred):
    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)

transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(
        shift_limit=0.05,
        scale_limit=0.1,
        rotate_limit=(-15, 15),
        p=1
    )
],additional_targets={'lung': 'image', 'infection': 'image'})

class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size=BATCH_SIZE, shuffle=False, transform=None) :
        super().__init__()
        self.df = df
        self.shuffle = shuffle
        self.batch_size = batch_size
        self.indexes = np.arange(len(df))
        self.transform = transform
        self.on_epoch_end()

    def __len__(self):
        return int(len(self.df) // self.batch_size)

    def on_epoch_end(self):
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __getitem__(self, index):
        X = np.empty((self.batch_size,IMAGE_SIZE,IMAGE_SIZE,3))
        y = np.empty((self.batch_size,IMAGE_SIZE,IMAGE_SIZE,2))
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        for i, img_path in enumerate(self.df['image'].iloc[indexes]):
            image = process_path(img_path, 'rgb')
            lung_path = self.df['lung'].iloc[indexes[i]]
            lung = process_path(lung_path).reshape((IMAGE_SIZE,IMAGE_SIZE))
            inf_path = self.df['infection'].iloc[indexes[i]]
            inf = process_path(inf_path).reshape((IMAGE_SIZE,IMAGE_SIZE))

            if self.transform:
                transformed = self.transform(image=image,lung=lung,infection=inf)
                image = transformed['image']
                lung = transformed['lung']
                inf = transformed['infection']

            X[i,] = image
            y[i,:,:,0] = lung
            y[i,:,:,1] = inf

        return X, y

sample = train_df[train_df['category'] == 'COVID-19'].sample(n=1)
sample_image = process_path(sample['image'].item())
sample_lung = process_path(sample['lung'].item())
sample_inf = process_path(sample['infection'].item())
plot_sample(sample_image,sample_lung,sample_inf)

sample_transformed = transform(image=sample_image,lung=sample_lung,infection=sample_inf)
plot_sample(
    image=sample_transformed['image'],
    lung_mask=sample_transformed['lung'],
    infection_mask=sample_transformed['infection']
)

sample= list(train_df[train_df['category']=='COVID-19'].sample(BATCH_SIZE*2).index)
sample += list(train_df[train_df['category']=='Non-COVID'].sample(BATCH_SIZE).index)
sample += list(train_df[train_df['category']=='Normal'].sample(BATCH_SIZE).index)

train_batch = DataGenerator(train_df[train_df.index.isin(sample)],shuffle=True,transform=transform)

for i in range(len(train_batch)):
    images, mask = train_batch[i]
    image=images[0,:,:,0]
    lung_mask=mask[0,:,:,0]
    infection_mask=mask[0,:,:,1]

    plot_sample(image,lung_mask,infection_mask)

sample_valid= list(valid_df[valid_df['category']=='COVID-19'].sample(BATCH_SIZE*2).index)
sample_valid += list(valid_df[valid_df['category']=='Non-COVID'].sample(BATCH_SIZE).index)
sample_valid += list(valid_df[valid_df['category']=='Normal'].sample(BATCH_SIZE).index)

valid_batch = DataGenerator(valid_df[valid_df.index.isin(sample)],shuffle=True,transform=transform)

for i in range(len(valid_batch)):
    images_valid, mask_valid = valid_batch[i]
    image_valid=images_valid[0,:,:,0]
    lung_mask_valid=mask_valid[0,:,:,0]
    infection_mask_valid=mask_valid[0,:,:,1]

    plot_sample(image_valid,lung_mask_valid,infection_mask_valid)

model = sm.Unet('resnet101',input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), classes=2, activation='sigmoid', encoder_weights='imagenet')
model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef,iou_coef])

checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'best_resunet',
    monitor='val_loss',
    verbose=1,
    save_best_only=True,
    mode='auto',
)

lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.5,
    patience=3,
    verbose=0,
    min_delta=1e-5,
)
train_gen = DataGenerator(train_df,shuffle=True, transform=transform)
valid_gen = DataGenerator(valid_df)
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=EPOCHS,
    callbacks=[checkpoint,lr_plateau],
)

model.save('resunet')

plt.figure(figsize=(15,5))
plt.subplot(1,3,1)
plt.plot(range(history.epoch[-1]+1),history.history['loss'],label='Train_Loss')
plt.plot(range(history.epoch[-1]+1),history.history['val_loss'],label='Val_loss')
plt.title('LOSS'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend();

plt.subplot(1,3,2)
plt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='Train_dice_coef')
plt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='Val_dice_coef')
plt.title('DICE'); plt.xlabel('Epoch'); plt.ylabel('dice_coef');plt.legend();

plt.subplot(1,3,3)
plt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Train_iou_coef')
plt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')
plt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend();
plt.show()

plt.figure(figsize=(18, 6))

# Subplot 1: Loss
plt.subplot(1, 3, 1)
plt.plot(range(history.epoch[-1] + 1), history.history['loss'], label='Train Loss', color='blue')
plt.plot(range(history.epoch[-1] + 1), history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# Subplot 2: Dice Coefficient
plt.subplot(1, 3, 2)
plt.plot(range(history.epoch[-1] + 1), history.history['dice_coef'], label='Train Dice Coef', color='green')
plt.plot(range(history.epoch[-1] + 1), history.history['val_dice_coef'], label='Validation Dice Coef', color='red')
plt.title('Dice Coefficient')
plt.xlabel('Epoch')
plt.ylabel('Dice Coefficient')
plt.legend()
plt.grid(True)

# Subplot 3: IOU Coefficient
plt.subplot(1, 3, 3)
plt.plot(range(history.epoch[-1] + 1), history.history['iou_coef'], label='Train IOU Coef', color='purple')
plt.plot(range(history.epoch[-1] + 1), history.history['val_iou_coef'], label='Validation IOU Coef', color='brown')
plt.title('IOU Coefficient')
plt.xlabel('Epoch')
plt.ylabel('IOU Coefficient')
plt.legend()
plt.grid(True)

# Overall Title
plt.suptitle('Training Metrics Progression', fontsize=16)

plt.tight_layout()
plt.show()

test_generator = DataGenerator(test_df, batch_size = 6, shuffle=True)
results = model.evaluate_generator(test_generator)
print(results)